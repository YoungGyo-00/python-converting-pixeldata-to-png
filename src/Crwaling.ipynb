{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import openpyxl as op\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "# cid(카테고리 id) 정의\n",
    "toCid = {'수납/정리': '019000000000000',\n",
    "        '주방/욕실/청소': '020000000000000',\n",
    "        '가구/인테리어': '022000000000000',\n",
    "        '사무/문구/디지털': '021000000000000',\n",
    "        '가전/레져/식품': '023000000000000',\n",
    "        '키즈/뷰티/패션잡화': '024000000000000',\n",
    "        '다이소 매장상품': '010000000000000',\n",
    "        '포장재 전문관': '027000000000000'}\n",
    "\n",
    "def write_data(item_list_xlsx, filename_xlsx, imgPath, sheet_name):\n",
    "\n",
    "    input_wb = op.load_workbook(item_list_xlsx)  # 입력을 읽어올 엑셀파일\n",
    "    input_ws = input_wb[sheet_name]\n",
    "    row_max = input_ws.max_row # 최대행값 저장\n",
    "\n",
    "    output_wb = op.load_workbook(filename_xlsx)  # 결과를 저장할 엑셀파일\n",
    "    output_ws = output_wb[sheet_name]\n",
    "\n",
    "    for r in range(2, row_max+1):  # 2행부터 마지막행까지 반복\n",
    "        categories = []\n",
    "        type = str(input_ws.cell(row=r, column=1).value)  # 물품분류\n",
    "        if type == 'None':\n",
    "            type = str(input_ws.cell(row=r-1, column=1).value)\n",
    "        search = str(input_ws.cell(row=r, column=2).value)  # 검색어\n",
    "        if search == 'None':\n",
    "            continue\n",
    "        search_include = str(input_ws.cell(row=r, column=3).value).split(', ')    # 포함단어\n",
    "        search_except = str(input_ws.cell(row=r, column=4).value).split(', ')     # 제외단어\n",
    "        # max_item = int(str(ws.cell(row=r, column=6).value)[5:-1])           # 총 물품 개수\n",
    "\n",
    "        for c in range(7, input_ws.max_column+1):  # 카테고리명을 리스트에 저장\n",
    "            category = str(input_ws.cell(r, c).value)\n",
    "            if category == 'None':\n",
    "                continue\n",
    "            categories.append(category)\n",
    "\n",
    "        print(\"-------------\" + search + \"-------------\")\n",
    "        num = 1  # 순번\n",
    "        for category in categories:  # 해당 검색어의 카테고리 하나씩 탐색\n",
    "            index1 = category.find('(')\n",
    "            index2 = category.find(')')\n",
    "            itemNum = int(category[index1+1:index2].replace(',', ''))\n",
    "            categoryPage = int(itemNum/50) + 1\n",
    "            if categoryPage > 150:  # 150 페이지가 넘어가는 경우 150 페이지까지만 탐색\n",
    "                categoryPage = 150\n",
    "            category = category[:index1]\n",
    "            try:\n",
    "                cid = toCid[category]  # 한글로 된 카테고리명을 url에서 쓰이는 cid로 변환\n",
    "            except:\n",
    "                print(category + \"---unknown category!\")\n",
    "                continue\n",
    "\n",
    "            print(\"-------------\" + category + \"-------------\")\n",
    "            for page in range(1, categoryPage+1):  # 1페이지부터 마지막 페이지까지 반복\n",
    "                print(page)\n",
    "\n",
    "                # 페이지 url에서 http 소스 읽어옴\n",
    "                url = \"https://www.daisomall.co.kr/shop/search.php?nset=1&page={}&max=50&search_text={}&orderby=daiso_ranking1&cid={}&depth=1\".format(page, search, cid)\n",
    "                res = requests.get(url, headers={'User-Agent':'Mozilla/5.0'})\n",
    "                res.raise_for_status()\n",
    "                soup = bs(res.text, \"lxml\")\n",
    "\n",
    "                # 해당 페이지에 나와 있는 상품을 모두 저장\n",
    "                items = soup.find_all(\"li\", {\"class\": \"float01 search_goods_list\"})\n",
    "\n",
    "                # 상품을 하나씩 탐색\n",
    "                for item in items:\n",
    "                    title = item.find('div', {\"style\": \"margin-top:10px;height:38px;\"})\n",
    "                    itemName = title.find('a').get(\"title\")  # 상품명\n",
    "                    flag = 0\n",
    "                    if itemName.find(\"<b>\") == -1:  # 상품명에 검색어가 포함되지 않은 항목 제외\n",
    "                        for word in search_include: # 검색어가 포함되지 않았으나 '포함단어' 리스트에 있는 단어를 포함한 경우 제외하지 않음\n",
    "                            if itemName.find(word) != -1:\n",
    "                                flag = 1\n",
    "                        if flag == 0:\n",
    "                            continue\n",
    "                    \n",
    "                    itemName = itemName.replace(\"<b>\", '')\n",
    "                    itemName = itemName.replace(\"</b>\", '')\n",
    "\n",
    "                    # 모든 상품에 일괄적으로 제외할 단어들\n",
    "                    if itemName.find(\"밀크북\") != -1:\n",
    "                        continue\n",
    "                    if itemName.find(\"양장\") != -1:\n",
    "                        continue\n",
    "                    \n",
    "                    # '제외단어' 리스트에 있는 단어가 하나라도 포함된 경우 제외\n",
    "                    flag = 0\n",
    "                    for word in search_except:\n",
    "                        if itemName.find(word) != -1:\n",
    "                            flag = 1\n",
    "                    if flag == 1:\n",
    "                        continue\n",
    "\n",
    "                    print(itemName)\n",
    "\n",
    "                    price = item.find('div', {\"style\": \"margin-top:12px;\"})  # 상품가격\n",
    "                    itemPrice = price.find('strong').text\n",
    "                    itemPrice = itemPrice.replace(\"원\", '')\n",
    "                    itemPrice = itemPrice.replace(\",\", '')\n",
    "\n",
    "                    img = item.find('div', {\"class\": \"goods_line_img\"})  # 상품 이미지 url\n",
    "                    imgUrl = img.find('img').get('src')\n",
    "                    imgName = \"{}{}.jpg\".format(search, num)  # 이미지 파일 이름 형식\n",
    "\n",
    "                    # 상품 이미지 다운로드\n",
    "                    urllib.request.urlretrieve(imgUrl, imgPath+imgName)\n",
    "\n",
    "                    itemId = item.find('a').get('href')  # 상품번호\n",
    "                    itemId = itemId[24:34]\n",
    "\n",
    "                    # 상품번호로 해당 상품의 상세페이지 url 접속해 http 소스 읽어옴\n",
    "                    itemUrl = \"https://www.daisomall.co.kr/shop/goods_view.php?id={}&depth=1&search_text={}\".format(itemId, search)\n",
    "                    try:\n",
    "                        itemRes = requests.get(itemUrl, headers={'User-Agent':'Mozilla/5.0'})\n",
    "                    except:\n",
    "                        print(\"request error!\")\n",
    "                        continue\n",
    "                    itemRes.raise_for_status()\n",
    "                    soupItem = bs(itemRes.text, \"lxml\")\n",
    "\n",
    "                    try:\n",
    "                        itemNum = soupItem.find('td', {\"class\": \"color_63 line_h160\"}).find('strong').text \n",
    "                    except:\n",
    "                        print(\"itemNum error!\")\n",
    "                        continue\n",
    "                    \n",
    "                    itemCategories = []\n",
    "                    for itemCategory in soupItem.find_all('option', {\"selected\": \"\"}):  # 해당 상품의 카테고리 저장\n",
    "                        if str(itemCategory).find(\"selected\") == -1:\n",
    "                            continue\n",
    "                        itemCategory = itemCategory.get_text()\n",
    "                        itemCategories.append(itemCategory)\n",
    "\n",
    "                    try:\n",
    "                        data = [type, None, search, num, int(itemNum), itemCategories[0]+\">\"+itemCategories[1]+\">\"+itemCategories[2], itemName, imgUrl, int(itemPrice), itemUrl]\n",
    "                    except:\n",
    "                        print(\"category error!\")\n",
    "                        continue\n",
    "                    output_ws.append(data)\n",
    "                    num+=1\n",
    "                    \n",
    "            output_wb.save(filename_xlsx)\n",
    "\n",
    "\n",
    "# 물품코드 로딩\n",
    "def load_code(item_list_xlsx, filename_xlsx, sheet_name):\n",
    "    wb = op.load_workbook(filename_xlsx)\n",
    "    ws = wb.active\n",
    "    code_wb = op.load_workbook(item_list_xlsx)\n",
    "    code_ws = code_wb['물품코드표']\n",
    "    row_max = ws.max_row\n",
    "    code_row_max = code_ws.max_row\n",
    "    \n",
    "    codeDic = {'item': 'code'}\n",
    "    for r in range(2, code_row_max+1):\n",
    "        code = str(code_ws.cell(row=r, column=1).value)\n",
    "        item = str(code_ws.cell(row=r, column=2).value)\n",
    "        desc = str(code_ws.cell(row=r, column=3).value)\n",
    "        if desc.find(\"삭제\") != -1:\n",
    "            continue\n",
    "        codeDic[item] = code\n",
    "\n",
    "    for r in range(2, row_max+1):\n",
    "        temp = str(ws.cell(row=r, column=1).value)\n",
    "        try:\n",
    "            ws.cell(row=r, column=2).value = int(codeDic[temp])\n",
    "        except:\n",
    "            print(\"Key error! --- \" + temp)\n",
    "            continue\n",
    "        \n",
    "    wb.save(filename_xlsx)\n",
    "\n",
    "# 중복 행 제거\n",
    "def drop_duplicates(filename_xlsx):\n",
    "    df = pd.read_excel(filename_xlsx, engine='openpyxl')  # 엑셀파일 읽어오기\n",
    "    df = df.drop_duplicates(subset='상품번호')  # 중복 행 제거\n",
    "    df.to_excel(filename_xlsx[:-5]+\"_dptest.xlsx\", index=False)\n",
    "\n",
    "# main 함수\n",
    "\n",
    "sheet_name = '고무장갑'\n",
    "item_list_xlsx = \"촬영 대상 물품 분류체계_v0.1_권혁진_다이소몰 크롤링 목록_일반물품.xlsx\"  # 읽어올 물품 리스트\n",
    "filename_xlsx = \"고무장갑_텍스트.xlsx\"  # 결과를 저장할 xlsx 파일 이름\n",
    "imgPath = \"item_img_고무장갑/\"  # 이미지 파일이 저장될 경로\n",
    "columns_name = [\"물품분류\", \"물품코드\", \"물품종\", \"순번\", \"상품번호\", \"카테고리\", \"상품명\", \"상품사진\", \"가격\", \"링크\"]  # 컬럼명 지정\n",
    "\n",
    "# #--- 새 엑셀파일 생성 시\n",
    "output_wb = op.Workbook()\n",
    "output_ws = output_wb.create_sheet(sheet_name)\n",
    "output_ws.append(columns_name)\n",
    "output_wb.save(filename_xlsx)\n",
    "\n",
    "# #--- 기존 엑셀파일에 추가 시\n",
    "# output_wb = op.load_workbook(filename_xlsx)  # 결과를 저장할 엑셀파일\n",
    "# output_ws = output_wb.create_sheet(sheet_name)\n",
    "# output_ws.append(columns_name)\n",
    "# output_wb.save(filename_xlsx)\n",
    "\n",
    "write_data(item_list_xlsx, filename_xlsx, imgPath, sheet_name)\n",
    "# drop_duplicates(filename_xlsx)\n",
    "# load_code(item_list_xlsx, filename_xlsx, sheet_name) # !!!!!! 주석처리 확인 !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵션 있는 상품 비고란에 적기\n",
    "import requests \n",
    "from bs4 import BeautifulSoup as bs\n",
    "from openpyxl import load_workbook\n",
    "from urllib import request\n",
    "\n",
    "HEADERS = {'User-Agent':'Mozilla/5.0'}\n",
    "FILE_PATH = \"주방용품.xlsx\"\n",
    "CLASS = \"goods_options required_option\" # 옵션 Class\n",
    "\n",
    "wb = load_workbook(FILE_PATH) \n",
    "ws = wb.active\n",
    "row_max = ws.max_row # 읽은 파일에서 맨 하단부 데이터까지 \n",
    "\n",
    "for row in range(2, row_max+1):\n",
    "    url = str(ws.cell(row=row, column=10).value)\n",
    "    res = requests.get(url, headers=HEADERS) # 상태 코드와 HTML 내용을 응답받음, User-Agent, 403 에러 처리를 위한 헤더\n",
    "    res.raise_for_status() # 에러 발생 유무 확인\n",
    "    soup = bs(res.text, \"lxml\") # lxml : 구문 분석 파서 -> string 을 의미 있는 HTML 문서로 파싱\n",
    "    print(\"check\")\n",
    "\n",
    "    try:\n",
    "        optionBox = soup.find(\"select\", {\"class\": CLASS}) # 가장 가까운 태그 <select> class 찾기 \n",
    "    except:\n",
    "        continue\n",
    "    options = []\n",
    "    try:\n",
    "        for option in optionBox.find_all('option'):\n",
    "            text = option.text\n",
    "            options.append(text)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    print(options)\n",
    "\n",
    "    option_str = '옵션' + '\\n'\n",
    "    for option in options:\n",
    "        option_str = option_str + str(option) + '\\n'\n",
    "\n",
    "    ws.cell(row=row, column=11).value = option_str\n",
    "\n",
    "wb.save(FILE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl as op\n",
    "\n",
    "def load_option(input, output):\n",
    "    input_wb = op.load_workbook(input)\n",
    "    input_ws = input_wb.active\n",
    "    row_max = input_ws.max_row # 최대행값\n",
    "\n",
    "    output_wb = op.load_workbook(output)\n",
    "    output_ws = output_wb.active\n",
    "    \n",
    "    for r in range(2, row_max+1): # 2행부터 마지막행까지 반복\n",
    "        row_data = []\n",
    "        for i in range(1, 11): # 입력 파일의 현재 행 데이터를 row_data 리스트에 저장\n",
    "            row_data.append(input_ws.cell(row=r, column=i).value)\n",
    "\n",
    "        url = row_data[9]  # 상품 url\n",
    "        try:\n",
    "            res = requests.get(url, headers={'User-Agent':'Mozilla/5.0'})  # url로 접속해 http 소스 받아옴\n",
    "            res.raise_for_status()\n",
    "            soup = BeautifulSoup(res.text, \"lxml\")\n",
    "            optionBox = soup.find(\"select\", {\"class\": \"goods_options required_option\"})\n",
    "            options = []\n",
    "            for option in optionBox.find_all('option'):  # 상품의 옵션들을 options 리스트에 저장                   \n",
    "                text = option.text\n",
    "                options.append(text)\n",
    "        except:\n",
    "            output_ws.append(row_data)\n",
    "            output_wb.save(output)\n",
    "            continue\n",
    "\n",
    "        if len(options) == 0:  # 만약을 대비해...ㅎ\n",
    "            output_ws.append(row_data)\n",
    "            output_wb.save(output)\n",
    "            continue\n",
    "        \n",
    "        origin_price = row_data[8]  # 옵션 선택으로 인한 추가 비용 합산 전 원래 가격\n",
    "        try:\n",
    "            int(origin_price)\n",
    "        except:\n",
    "            output_ws.append(row_data)\n",
    "            output_wb.save(output)\n",
    "            continue\n",
    "\n",
    "        for i in range(1, len(options)): # 저장해둔 옵션들을 하나씩 탐색\n",
    "            add_price = 0\n",
    "            if options[i].find('품절') != -1:  # 품절상품 제외\n",
    "                continue\n",
    "\n",
    "            if options[i].find('+') != -1:  # 추가 비용이 붙는 옵션의 경우\n",
    "                index_1 = options[i].find('+')\n",
    "                index_2 = options[i].find('원')\n",
    "                add_price = options[i][index_1:index_2].replace(',', '')\n",
    "                try:\n",
    "                    row_data[8] = origin_price + int(add_price)\n",
    "                except:\n",
    "                    continue\n",
    "            if options[i].find('-') != -1:  # 가격이 절감되는 옵션의 경우\n",
    "                index_1 = options[i].find('-')\n",
    "                index_2 = options[i].find('원')\n",
    "                add_price = options[i][index_1:index_2].replace(',', '')\n",
    "                try:\n",
    "                    row_data[8] = origin_price - int(add_price)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            row_data.append(options[i]) \n",
    "            output_ws.append(row_data)  # 출력파일에 현재 행 데이터 쓰기 \n",
    "            print(row_data[6] + '------------' + options[i])\n",
    "\n",
    "            row_data[8] = origin_price   # 변동되었던 가격 복구\n",
    "            row_data.remove(options[i])  # 다음 옵션을 위해 옵션 칸 비우기\n",
    "\n",
    "        output_wb.save(output) # 저~장~\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    input = \"잡화 슈즈 명품.xlsx\"           # 입력 파일 이름\n",
    "    output = \"잡화 슈즈 명품_옵션.xlsx\"     # 출력 파일 이름      \n",
    "    columns_name = [\"물품분류\", \"물품코드\", \"물품종\", \"순번\", \"상품번호\", \"카테고리\", \"상품명\", \"상품사진\", \"가격\", \"링크\", \"비고\"] # 컬럼명 지정\n",
    "\n",
    "    # --- 새 엑셀파일 생성 시 --- #\n",
    "    output_wb = op.Workbook()\n",
    "    output_ws = output_wb.active\n",
    "    output_ws.append(columns_name)\n",
    "    output_wb.save(output)\n",
    "    \n",
    "    load_option(input, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
